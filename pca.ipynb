{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Multiclass SVM Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7909fedaf0f8d4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a093d515b7093878"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, roc_curve, auc\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from skimage.feature import hog\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-13T07:28:19.830030900Z"
    }
   },
   "id": "404e8a20b7185ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4934a5032c0d0a6"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "name_path = './archive/lfw_allnames.csv'\n",
    "images_path = './archive/lfw-deepfunneled/lfw-deepfunneled'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:28:19.830030900Z",
     "start_time": "2023-12-13T07:28:19.830030900Z"
    }
   },
   "id": "ab3aaaaa62e20034"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only use classes with at least 100 images to simplify the problem."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22145e0a6d76dc39"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "df_names = pd.read_csv(name_path)\n",
    "min_faces_per_person = 100\n",
    "df_names = df_names.loc[df_names[\"images\"] >= min_faces_per_person, :]\n",
    "names = list(df_names[\"name\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:28:20.002310900Z",
     "start_time": "2023-12-13T07:28:19.845660400Z"
    }
   },
   "id": "4c9ed38c21cdaf13"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Colin_Powell, number of samples: 236.\n",
      "Class: Donald_Rumsfeld, number of samples: 121.\n",
      "Class: George_W_Bush, number of samples: 530.\n",
      "Class: Gerhard_Schroeder, number of samples: 109.\n",
      "Class: Tony_Blair, number of samples: 144.\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for name in names:\n",
    "    dir_path = os.path.join(images_path, name)\n",
    "    list_images_name = os.listdir(dir_path)\n",
    "    for image_name in list_images_name:\n",
    "        image_path = os.path.join(dir_path, image_name)\n",
    "        img_rgb = plt.imread(image_path)\n",
    "        X.append(img_rgb)\n",
    "        Y.append(name)\n",
    "    print(f\"Class: {name}, number of samples: {len(list_images_name)}.\")\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:28:21.360193300Z",
     "start_time": "2023-12-13T07:28:20.002310900Z"
    }
   },
   "id": "1ea42919fb8d04eb"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def create_features(img, show_hog=False):\n",
    "    # flatten image\n",
    "    color_features = img.flatten()\n",
    "    # convert image to greyscale\n",
    "    grey_image = np.array(0.299 * img[:, :, 0] + 0.587 * img[:, :, 1] + 0.114 * img[:, :, 2])\n",
    "    # get HOG features from greyscale image\n",
    "    hog_features, hog_image = hog(grey_image, visualize=True, block_norm='L2-Hys', pixels_per_cell=(16, 16))\n",
    "    if show_hog:\n",
    "        plt.imshow(hog_image, cmap=\"gray\")\n",
    "    # combine color and hog features into a single array\n",
    "    flat_features = np.hstack((color_features, hog_features))\n",
    "    return flat_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:28:21.360193300Z",
     "start_time": "2023-12-13T07:28:21.357592400Z"
    }
   },
   "id": "b34685c27d5ba0b5"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "feature_matrix = []\n",
    "for x in X:\n",
    "    feature_matrix.append(create_features(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:28:40.108517400Z",
     "start_time": "2023-12-13T07:28:21.360193300Z"
    }
   },
   "id": "17369b620cc0faa3"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape is:  (1140, 201189)\n",
      "PCA matrix shape is:  (1140, 500)\n"
     ]
    }
   ],
   "source": [
    "# get shape of feature matrix\n",
    "feature_matrix = np.asarray(feature_matrix)\n",
    "print('Feature matrix shape is: ', feature_matrix.shape)\n",
    "\n",
    "# define standard scaler\n",
    "ss = StandardScaler()\n",
    "# run this on our feature matrix\n",
    "bees_stand = ss.fit_transform(feature_matrix)\n",
    "\n",
    "pca = PCA(n_components=500)\n",
    "# use fit_transform to run PCA on our standardized matrix\n",
    "pca.fit(bees_stand)\n",
    "X_pca = pca.transform(bees_stand)\n",
    "print('PCA matrix shape is: ', X_pca.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:29:19.019796100Z",
     "start_time": "2023-12-13T07:28:40.108517400Z"
    }
   },
   "id": "7d153c2bdb794e43"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# label_encoder object knows  \n",
    "# how to understand word labels. \n",
    "label_encoder = LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "Y = label_encoder.fit_transform(Y) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:29:19.135536100Z",
     "start_time": "2023-12-13T07:29:19.036102500Z"
    }
   },
   "id": "665b523e21e243c"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_pca, Y, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:29:19.215743200Z",
     "start_time": "2023-12-13T07:29:19.145726100Z"
    }
   },
   "id": "7754662fcb3af05d"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Predictions: [2 2 1 3 1 0 2 0 2 0 4 0 2 2 4 3 2 2 2 0 0 2 3 0 0 0 2 1 3 0 0 2 2 2 2 2 2\n",
      " 2 2 4 1 2 2 0 4 1 0 4 3 1 2 2 2 2 4 0 4 1 0 3 2 2 0 2 4 2 2 4 2 2 2 4 2 2\n",
      " 2 1 2 2 2 0 1 0 3 2 2 2 2 2 0 2 3 4 2 0 2 2 1 1 1 2 2 0 4 2 2 0 1 1 2 2 2\n",
      " 3 2 3 2 2 2 2 0 0 0 0 1 2 3 4 3 4 2 2 2 4 0 2 2 0 2 2 0 3 4 2 2 3 0 2 0 1\n",
      " 2 2 4 0 2 4 2 0 4 2 2 1 2 2 1 1 0 2 2 2 3 4 0 4 3 0 0 2 2 0 2 0 0 0 2 0 0\n",
      " 2 2 1 4 0 4 3 0 1 2 4 2 4 2 1 3 2 0 2 2 0 1 4 2 0 0 2 2 2 2 2 2 2 1 0 2 2\n",
      " 2 0 2 0 2 0 0 2 4 0 3 1 2 3 4 0 2 2 2 2 2 2 1 4 2 2 2 2 2 2 1 1 2 3 0 0 3\n",
      " 0 2 0 2 2 2 2 2 2 2 3 1 3 1 1 0 2 4 0 0 2 0 0 2 2 4]\n",
      "Accuracy: 0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "class SVM:\n",
    "    def __init__(self, learning_rate=0.001, _lambda=2, epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self._lambda = _lambda\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def train(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "        num_classes = len(unique_classes)\n",
    "\n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.zeros((num_classes, num_features))\n",
    "        self.bias = np.zeros(num_classes)\n",
    "\n",
    "        # One-vs-All training\n",
    "        for c in range(num_classes):\n",
    "            binary_labels = np.where(y == unique_classes[c], 1, -1)\n",
    "\n",
    "            for epoch in range(self.epochs):\n",
    "                for i in range(num_samples):\n",
    "                    xi = X[i]\n",
    "                    yi = binary_labels[i]\n",
    "\n",
    "                    # Update weights and bias using the SVM update rule\n",
    "                    if yi * (np.dot(self.weights[c], xi) + self.bias[c]) <= 1:\n",
    "                        self.weights[c] += self.learning_rate * (yi * xi - self._lambda * self.weights[c])\n",
    "                        self.bias[c] += self.learning_rate * yi\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions using the trained SVM\n",
    "        predictions = []\n",
    "        for xi in X:\n",
    "            scores = np.dot(self.weights, xi) + self.bias\n",
    "            predicted_class = np.argmax(scores)\n",
    "            predictions.append(predicted_class)\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming train_mat is your training data and train_label is the corresponding labels\n",
    "# Ensure that your labels are encoded as integers (e.g., 0, 1, 2, ...) for multiclass classification\n",
    "\n",
    "# Assuming train_mat is your training data and train_label is the corresponding labels\n",
    "# Ensure that your labels are encoded as integers (e.g., 0, 1, 2, ...) for multiclass classification\n",
    "\n",
    "# Create and train the SVM model\n",
    "svm_model = SVM()\n",
    "svm_model.train(X_train, Y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "# Assuming test_mat is your test data\n",
    "test_predictions = svm_model.predict(X_test)\n",
    "print(\"Test Predictions:\", test_predictions)\n",
    "accuracy = np.mean(test_predictions == Y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T07:29:48.908980100Z",
     "start_time": "2023-12-13T07:29:42.482150400Z"
    }
   },
   "id": "39ea6ef1b92fdc49"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
